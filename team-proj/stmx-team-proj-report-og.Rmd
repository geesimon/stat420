---
title: "Proposal: Residential Housing Price Prediction"
author: "STAT 420, Summer 2017, Martynas Sapoka (netid:?), Shailender Singh (netid: ?), Tesa Ho (netid: tnho2), Xiaoming Ji (netid: xj9)"
netid: ""
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
---


#Introduction
##Overview

We propose to create a linear model that can predict residential home prices in Ames, Iowa based on several explanatory variables.  This project is a practical example of using real world data that consists of a mix of different data types - nominal, ordinal, discrete, and continuous variables. 

Our final project will incorporate the following topics covered in this course: 

- Variable manipulation
- Outlier identification
- Data analysis and interpretation
- Model building
- Model evaluation

##Description of Dataset

The data set describes the sale of individual residential property in Ames, Iowa from 2006 to 2010 and contains 2,919 observations.  There are 80 explanatory variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home values.

The 23 nominal variables identify various types of dwellings, materials, garages, and environmental conditions.

The 23 ordinal variables range from 2 to 28 representing Streets (gravel or paved) and Neighborhoods (areas within the Ames city limits).

The 14 discrete variables quantify the number of items for each house.  Items include the number of kitchens, bedrooms, bathrooms, garage spaces and their respective location if the house has more than one floor. 

The 20 continuous variables are related to area dimensions for each house.  Variables include total dwelling square footage, total lot size, living area, and room dimensions. 

Some important variables that may have strong correlation with sale price.

- `MSZoning`: Identifies the general zoning classification of the sale.
- `LotArea`:  Lot size in square feet.
- `OverallQual`: Overall material and finish quality.
- `TotalBsmtSF`: Total square feet of basement area.
- `YearBuilt`: Original construction date.
- `BedroomAbvGr`: Bedrooms above grade (does NOT include basement bedrooms).
- `BsmtFullBath`:  Full bathrooms above grade.
- `GarageCars`: Size of garage in car capacity.

##Dataset Source

Inspired by [`Kaggle Competition`](https://www.kaggle.com/c/house-prices-advanced-regression-techniques), the data set is provided by Dean De Cock from Truman State University.  The raw data comes directly from the Iowa State Assessorʻs Office. The initial Excel file contained 113 variables describing 3,970 property sales that had occurred in Ames, Iowa between 2006 and 2010. 
The variables were a mix of nominal, ordinal, continuous, and discrete variables used in calculation of assessed values and included physical property measurements in addition to computation variables used in the city’s assessment process. Variables that required specific housing or assessing knowledge or previous calculations were removed from the final dataset.  

# Methods
## Data Preprocessing 
```{r, include=FALSE}
library(readr)
house_data = read_csv("HousePrices/train.csv")
head(house_data)
```

Change column name to comply with R variable definition
```{r}
BadNames =  c(FirstFlrSF = "1stFlrSF", SecondFlrSF = "2ndFlrSF", ThreeSsnPorch = "3SsnPorch")

for (i in 1:length(BadNames)) {
  colnames(house_data)[which(colnames(house_data) == BadNames[i])] = names(BadNames[i])
}
```
- Convert categorical predictor to factor and make NA an extra value
- Remove predictor with too many NAs (> 50%). In our data, NA is not a invalid value for most categorical predictors, but too many NA makes this predictor not very useful.
- Replace numerical NA with mean

```{r}
#Combine FullBath and HalfBath
house_data$Bath = house_data$FullBath + house_data$HalfBath * 0.5
house_data = subset(house_data, select = -c(Id, FullBath, HalfBath))

CategoricalNames = c("MSSubClass", "MSZoning", "Street", "Alley", "LotShape",
            "LandContour", "Utilities", "LotConfig", "LandSlope", 
            "Neighborhood", "Condition1", "Condition2", "BldgType", 
            "HouseStyle", "OverallQual", "OverallCond", "RoofStyle", 
            "RoofMatl", "Exterior1st", "Exterior2nd", "MasVnrType",
            "ExterQual", "ExterCond", "Foundation", "BsmtQual", 
            "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", 
            "Heating", "HeatingQC", "CentralAir", "Electrical", 
#           "BsmtFullBath", "BsmtHalfBath", 
#           "FullBath","HalfBath", 
#           "BedroomAbvGr", "KitchenAbvGr",
            "KitchenQual", "Functional", 
#           "TotRmsAbvGrd",
#            "Fireplaces",
            "FireplaceQu", 
            "GarageType","GarageFinish", 
#           "GarageCars",
            "GarageQual", "GarageCond", 
            "PavedDrive", "PoolQC", "Fence", "MiscFeature", 
            "SaleType", "SaleCondition")

rm_index = c()
for(i in 1:ncol(house_data)) {
  nas = is.na(house_data[[i]])
  
  if(sum(nas) / nrow(house_data) > 0.5) {
    print(paste("(", colnames(house_data)[i], ") Removed"))
    rm_index = c(rm_index, i)
    
  } else {
    if(colnames(house_data)[i] %in% CategoricalNames) { #Categorical predictor
      house_data[[i]] = factor(house_data[[i]], exclude = NULL)
    } else{
      if(sum(nas) > 0) {
        house_data[[i]][nas] = mean(house_data[[i]][!nas])
      }
    }
  }
}

CategoricalNames = CategoricalNames[!(CategoricalNames %in% colnames(house_data)[rm_index])]
house_data = subset(house_data, select = -rm_index)
```

$## Correlation pairs plot##$

```{r}
# number of corr plots
house_cols = colnames(house_data)
x = (length(house_cols)-1)/10

for (i in 0:(x-1)){
  #pairs(num_house_data[, c(house_cols[(10*i+1):(10*(i+1))], "SalePrice")], col="dodgerblue")
}

``` 


$## Examine non-factor variables ##$

```{r}
non_factors = c("LotFrontage", "LotArea", "YearBuilt", 
                "YearRemodAdd", "MasVnrArea", "BsmtFinSF1",
                "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", 
                "LowQualFinSF", 
                "GrLivArea", "BsmtFullBath", "BsmtHalfBath",
                "BedroomAbvGr", "KitchenAbvGr", 
                "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt",
                "GarageCars", "GarageArea", "WoodDeckSF", 
                "OpenPorchSF", "EnclosedPorch",  
                "ScreenPorch", "PoolArea", "MiscVal", "SalePrice")

nf_data = data.frame(sapply(house_data[, non_factors], function(x) as.numeric(x)))
colnames(nf_data) = non_factors
nf_corr = cor(nf_data)
sort(nf_corr["SalePrice",], decreasing=TRUE)
```

$## Histogram ##$

Histograms of the non-factor variables that are significant.

```{r}
top_corrs = sort(nf_corr["SalePrice", ], decreasing=TRUE)[sort(nf_corr["SalePrice", ], decreasing=TRUE) > 0]
top_corrs_name = names(top_corrs[2:length(top_corrs)])

par(mfrow=c(4,3))
for (name in top_corrs_name[1:12]){
  hist(nf_data[,name], breaks=20, xlab=name, main="hist ", col="dodgerblue")
}

par(mfrow=c(4,3))
for (name in top_corrs_name[13:length(top_corrs_name)]){
  hist(nf_data[,name], breaks=20, xlab=name, main="hist ", col="dodgerblue")
}
```

$## SalePrice vs Top Correlated Features ##$

```{r}
par(mfrow=c(3,3))
for (name in top_corrs_name[1:9]){
  plot(nf_data[,name], house_data$SalePrice, xlab=name, ylab="SalePrice", col="blue")
  p_mod = lm(house_data$SalePrice ~ nf_data[,name])
  abline(coef(p_mod)[1], coef(p_mod)[2], col="orange", lwd=2)
}

par(mfrow=c(3,3))
for (name in top_corrs_name[10:18]){
  plot(nf_data[,name], house_data$SalePrice, xlab=name, ylab="SalePrice", col="blue")
  p_mod = lm(house_data$SalePrice ~ nf_data[,name])
  abline(coef(p_mod)[1], coef(p_mod)[2], col="orange", lwd=2)
}

par(mfrow=c(3,3))
for (name in top_corrs_name[19:length(top_corrs_name)]){
  plot(nf_data[,name], house_data$SalePrice, xlab=name, ylab="SalePrice", col="blue")
  p_mod = lm(house_data$SalePrice ~ nf_data[,name])
  abline(coef(p_mod)[1], coef(p_mod)[2], col="orange", lwd=2)
}
```

## Model Evaluation 


```{r, message=FALSE, include=FALSE}
#Utility functions

library(lmtest)
get_bp_decision = function(model, alpha) {
  decide = unname(bptest(model)$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_sw_decision = function(model, alpha) {
  decide = unname(shapiro.test(resid(model))$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  plot(fitted(model), resid(model), 
       col = pointcol, pch = 20, cex = 1.5,
       xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}

plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
  qqline(resid(model), col = linecol, lwd = 2)
}

build_formula = function(response_name, predictor_names, interaction = 1) {
  str_formula = paste(response_name, " ~ (")
  
  add_plus = FALSE
  for (predictor_name in predictor_names) {
    if(add_plus) str_formula = paste(str_formula, "+ ")
    else add_plus = TRUE
    
    str_formula = paste(str_formula, predictor_name)
  }
  str_formula = paste(str_formula, ")")
  
  if(interaction > 1) str_formula = paste(str_formula, "^ ", interaction)
  
  as.formula(str_formula)
}
```


We select the significant predictors that have high correlation with SalePrice
```{r}
num_house_data = house_data
for(name in colnames(num_house_data)){
  if(is.factor(num_house_data[[name]])) 
    num_house_data[[name]] = as.numeric(num_house_data[[name]])
}

all_cor = cor(num_house_data)
(sig_cor = sort(abs(all_cor["SalePrice", abs(all_cor["SalePrice",]) > 0.5]), decreasing = TRUE)[-1])
```

We first build a model with predictors that has cor values > 0.5
```{r}
library(faraway)
sig_model = lm(build_formula("log(SalePrice)", names(sig_cor)), data = house_data)
summary(sig_model)$adj.r.squared
sort(vif(sig_model)[vif(sig_model) > 5], decreasing = TRUE)
```
This model has good adjusted r-squared value. However, we do see many predictors has high VIFs. Although, high VIFs won't cause big problem to prediction, too many correlated predictors dose impact our capability to search through other better models using interaction or polynomial. This could also cause problem to analyze high leverage and calculate LOOCV RMSE because not able to solve $\left(X^\top X\right)^{-1}$.

We see `OverallQual` gives us the most trouble although  VIF of `OverallQual2` is `r vif(sig_model)["OverallQual2"][[1]]`. Let's first try to remove this predictor and see what happen.
```{r}
predictors = names(sig_cor)[names(sig_cor) != "OverallQual"]
no_overallqual_model = lm(build_formula("log(SalePrice)", predictors), data = house_data)
summary(no_overallqual_model)$adj.r.squared
anova(no_overallqual_model, sig_model)[2, "Pr(>F)"]
```
However, after removing `OverallQual`, adjusted r-squared dropped `r summary(sig_model)$adj.r.squared - summary(no_overallqual_model)$adj.r.squared`, the significant test also reject the $OverallQual = 0$ hypothesis.  All these evidences mean `OverallQual` is useful for our predicction.

Let's check the relation between `OverallQual` and `Log(SalePrice)`
```{r, echo=FALSE}
boxplot(log(SalePrice) ~ OverallQual, data = house_data, col = "darkorange", border = "dodgerblue")
```

It's quite linear and increase of 1 score of OverallQual has constant change on `log(SalePrice)`. Thus, we could convert this categorical predictor to numerical predictor.

```{r}
house_data$OverallQual = as.numeric(house_data$OverallQual)
model_1 = lm(build_formula("log(SalePrice)", names(sig_cor)), data = house_data)
summary(model_1)$adj.r.squared
```

Let's do the similar check on `ExterQual` 
```{r}
predictors = names(sig_cor)[names(sig_cor) != "ExterQual"]
model_2 = lm(build_formula("log(SalePrice)", predictors), data = house_data)
summary(model_2)$adj.r.squared
anova(model_2, model_1)[2, "Pr(>F)"]
```
Interesting enough, by removing `ExterQual`, the adjusted r-squared wasn't changed much. The signifciant test also fail to reject the $ExterQual = 0$ hypothesis.

The VIFs of `GarageCars`, `TotalBsmtSF`, `KitchenQual`, `BsmtQual` and `GrLivArea` aren't that big. We perform search to find the best model.
```{r}
model_aic = step(model_2, direction="backward", trace=0)
model_bic = step(model_2, direction="backward", k = log(nrow(house_data)), trace=0)
(rmse_aic  = get_loocv_rmse(model_aic))
(rmse_bic  = get_loocv_rmse(model_bic))

if(rmse_aic < rmse_aic) {
  start_model = model_aic
} else {
  start_model = model_bic
}
coef(start_model)
```
According to LOOCV RMSE, BIC search gives us the best model to start. This model is very good for interpretation as it balances between number of predictors and RMSE. Since our goal it to make best predition, we should explore furthur to find the model with best RMSE.

```{r}
start_predictors = attr(summary(start_model)$term,"term.labels")
remaining_predictors = colnames(house_data)[!colnames(house_data) %in% c(names(sig_cor), "SalePrice")]

#model = step(start_model, scope = build_formula("log(SalePrice)", all_predictors), direction = "forward", trace=0)
```

##Test Models 

To verify each modelʻs predictive power, we split the data set into a training and test set and re-train the model on the training data.
$## Split Model into Train & Test Sets ##$

```{r}
set.seed(42)
train_index = sample(1:nrow(house_data), nrow(house_data)*2/3) # randomly chosen observations for training
train_data  = house_data[train_index, ]
test_data   = house_data[-train_index, ]
# retrain
model_1 = lm(build_formula("log(SalePrice)", names(sig_cor)), data = train_data)
model_2 = lm(build_formula("log(SalePrice)", predictors), data = train_data)
model_aic = step(model_2, direction="backward", trace=0)
model_bic = step(model_2, direction="backward", k = log(nrow(train_data)), trace=0)
```

Compare models on test data using RMSE as metric.

```{r}
## function to calculate rmse
rmse  = function(actual, predicted) {
  sqrt(mean((actual - predicted) ^ 2, na.rm=TRUE))
}

## function to compare models using rmse 
compareModels <- function(models, modelNames){
  train_error = rep(0, length(modelNames))
  test_error = rep(0, length(modelNames))
  for (i in 1:length(modelNames)){
    ## train errors
    train_error[i] = rmse(log(train_data$SalePrice), predict(models[[ modelNames[i] ]], newdata=train_data))
    ## test errors
    test_error[i] = rmse(log(test_data$SalePrice), predict(models[[ modelNames[i] ]], newdata=test_data))
  }
  df = data.frame("models"=modelNames, "trainErrors"=train_error, "testErrors"=test_error)
  return(df)
}

plot_errors <- function(testData, model, model_name){
  ndf = data.frame("SalePrice"=log(testData["SalePrice"]), "pred.SalePrice" = predict(model, 
                  newdata=testData))
  plot(ndf$SalePrice - ndf$pred.SalePrice, col = "blue", ylab = "Pred Errors", main = model_name)
}

```
# Results

The previous model comparison determined that the BIC was the best model based on the entire housing data set.  The model was then re-trained on the training data set to predict the SalesPrice of the test data set.  Using the RMSE for comparison, the BIC model outperformed the other models.

```{r}
## ADD MORE MODELS HERE TO COMPARE
modelNames = c("model_1", "model_2", "model_aic", "model_bic")
models = vector(mode="list", length = length(modelNames))
models[["model_1"]] = model_1
models[["model_2"]] = model_2
models[["model_aic"]] = model_aic
models[["model_bic"]] = model_bic

compareModels(models, modelNames)
```

The prediction errors for each model were also very similar.

```{r}
## ADD MORE MODELS HERE TO COMPARE
par(mfrow=c(2, 2))
plot_errors(test_data, model_1, "model_1")
plot_errors(test_data, model_2, "model_2")
plot_errors(test_data, model_aic, "model_aic")
plot_errors(test_data, model_bic, "model_bic")
```



# Discussion
- Whether we should make discrete variables in regression model a categorical predictors?

The way to discern an interval/ratio variable is to ask if every unit increment in the variable indicates the same amount of increment in the context you wish you measure. For instance, the jump from 35 to 36 degrees is the same as the jump from 43 to 44; it's the same amount of temperature difference. Likewise, the jump from 100 to 101 subscribers is the same as the jump from 1009 to 1010 subscribers. As long as this is true, your regression coefficient of that independent variable will make sense, because you can legitimately interpret it as the slope of the regression line.

General confusion appears when you mix in ordinal data, such as those 5-point "how satisfied are you?" questions. They are expressed in whole number, very easily to be confused with discrete data. However, each jump in the scale does not necessarily mean the same thing. E.g. a jump from "4: happy" to "5: very happy" is not necessarily the same as a jump from "1: very unhappy" to "2: unhappy." In that case, the variable should not be put into the regression as is, but treated differently (search "dummy variable in regression" to learn more.)

- Model Assumption 

- Kaggle Score


#Appendix
- [`Kaggle Competition`](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- Book
    - Applied Statistics with R by David Dalpiaz
    - An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani
- [`Examining your data`](http://www.personal.psu.edu/jxb14/M554/articles/Hair%20et%20al%202010%20--%20Chapter%202.pdf)
